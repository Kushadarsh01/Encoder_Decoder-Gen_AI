{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd5a7e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df32fa0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Extract ZIP\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"fra-eng.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "print(\"Extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff4287e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Load and Clean Data\n",
    "def load_data(path='fra.txt', num_examples = 50000):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        lines = f.read().strip().split('\\n')\n",
    "    \n",
    "    pairs = [line.split('\\t')[:2] for line in lines[:num_examples]]\n",
    "    \n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    for eng, fra in pairs:\n",
    "        input_texts.append(eng)\n",
    "        target_texts.append(f\"<start> {fra} <end>\")\n",
    "    \n",
    "    return input_texts, target_texts\n",
    "\n",
    "input_texts, target_texts = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b5f32ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Tokenize\n",
    "input_tokenizer = Tokenizer(filters='')\n",
    "target_tokenizer = Tokenizer(filters='')\n",
    "\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "target_tokenizer.fit_on_texts(target_texts)\n",
    "\n",
    "input_seqs = input_tokenizer.texts_to_sequences(input_texts)\n",
    "target_seqs = target_tokenizer.texts_to_sequences(target_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "782b9ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: (50000, 7)\n",
      "Target tensor shape: (50000, 14)\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Pad sequences\n",
    "input_tensor = pad_sequences(input_seqs, padding='post')\n",
    "target_tensor = pad_sequences(target_seqs, padding='post')\n",
    "\n",
    "print(\"Input tensor shape:\", input_tensor.shape)\n",
    "print(\"Target tensor shape:\", target_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6830f757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vocab size: 9130\n",
      "Target vocab size: 17458\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Vocabulary Sizes\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
    "\n",
    "print(\"Input vocab size:\", input_vocab_size)\n",
    "print(\"Target vocab size:\", target_vocab_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e807b",
   "metadata": {},
   "source": [
    "task 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c35ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aac58c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 512\n",
    "\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fad0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(input_vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_lstm = LSTM(units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "# Save encoder states to initialize decoder\n",
    "encoder_states = [state_h, state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b051b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(target_vocab_size, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(target_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08958b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, None, 256)    2337280     ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, None, 256)    4469248     ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, 512),        1574912     ['embedding_2[0][0]']            \n",
      "                                 (None, 512),                                                     \n",
      "                                 (None, 512)]                                                     \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  [(None, None, 512),  1574912     ['embedding_3[0][0]',            \n",
      "                                 (None, 512),                     'lstm_2[0][1]',                 \n",
      "                                 (None, 512)]                     'lstm_2[0][2]']                 \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, None, 17458)  8955954     ['lstm_3[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,912,306\n",
      "Trainable params: 18,912,306\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd57b257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first <start> token from target and prepare as labels\n",
    "decoder_target_data = target_tensor[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e61031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4000/4000 [==============================] - 69s 17ms/step - loss: 0.2120 - val_loss: 1.8812\n",
      "Epoch 2/5\n",
      "4000/4000 [==============================] - 69s 17ms/step - loss: 0.1724 - val_loss: 1.9078\n",
      "Epoch 3/5\n",
      "4000/4000 [==============================] - 75s 19ms/step - loss: 0.1690 - val_loss: 1.9335\n",
      "Epoch 4/5\n",
      "4000/4000 [==============================] - 72s 18ms/step - loss: 0.1656 - val_loss: 1.9618\n",
      "Epoch 5/5\n",
      "4000/4000 [==============================] - 69s 17ms/step - loss: 0.1621 - val_loss: 1.9569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df9aab0d30>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "model.fit(\n",
    "    [input_tensor, target_tensor[:, :-1]],\n",
    "    tf.expand_dims(decoder_target_data, -1),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1de6de",
   "metadata": {},
   "source": [
    "task 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27fd3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder model for inference (takes input sentence, returns hidden states)\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38139d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder inputs\n",
    "decoder_state_input_h = Input(shape=(units,))\n",
    "decoder_state_input_c = Input(shape=(units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Decoder embedding\n",
    "dec_emb_inf = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# LSTM with previous states\n",
    "decoder_outputs_inf, state_h_inf, state_c_inf = decoder_lstm(\n",
    "    dec_emb_inf, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states_inf = [state_h_inf, state_c_inf]\n",
    "decoder_outputs_inf = decoder_dense(decoder_outputs_inf)\n",
    "\n",
    "# Full decoder inference model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs_inf] + decoder_states_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "48be899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_idx_word = {i: w for w, i in target_tokenizer.word_index.items()}\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Start with <start> token\n",
    "    target_seq = np.array([[target_tokenizer.word_index['<start>']]])\n",
    "\n",
    "    decoded_sentence = ''\n",
    "    stop_condition = False\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample the token with highest probability (greedy search)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = target_idx_word.get(sampled_token_index, '')\n",
    "\n",
    "        if sampled_word == '<end>' or len(decoded_sentence.split()) > 50:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_word\n",
    "\n",
    "        # Update the target sequence and states\n",
    "        target_seq = np.array([[sampled_token_index]])\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e6f3c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Input    : Go.\n",
      "Predicted: marche.\n",
      "Target   : Va !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Input    : Go.\n",
      "Predicted: marche.\n",
      "Target   : Marche.\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Input    : Go.\n",
      "Predicted: marche.\n",
      "Target   : En route !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Input    : Go.\n",
      "Predicted: marche.\n",
      "Target   : Bouge !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Input    : Hi.\n",
      "Predicted: salut !\n",
      "Target   : Salut !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Input    : Hi.\n",
      "Predicted: salut !\n",
      "Target   : Salut.\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Input    : Run!\n",
      "Predicted: cours !\n",
      "Target   : Cours !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Input    : Run!\n",
      "Predicted: cours !\n",
      "Target   : Courez !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Input    : Run!\n",
      "Predicted: cours !\n",
      "Target   : Prenez vos jambes à vos cous !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Input    : Run!\n",
      "Predicted: cours !\n",
      "Target   : File !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Input    : Run!\n",
      "Predicted: cours !\n",
      "Target   : Filez !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Input    : Run!\n",
      "Predicted: cours !\n",
      "Target   : Cours !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Input    : Run!\n",
      "Predicted: cours !\n",
      "Target   : Fuyez !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Input    : Run!\n",
      "Predicted: cours !\n",
      "Target   : Fuyons !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Input    : Run.\n",
      "Predicted: cours !\n",
      "Target   : Cours !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Input    : Run.\n",
      "Predicted: cours !\n",
      "Target   : Courez !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Input    : Run.\n",
      "Predicted: cours !\n",
      "Target   : Prenez vos jambes à vos cous !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Input    : Run.\n",
      "Predicted: cours !\n",
      "Target   : File !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Input    : Run.\n",
      "Predicted: cours !\n",
      "Target   : Filez !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Input    : Run.\n",
      "Predicted: cours !\n",
      "Target   : Cours !\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Pick 5 random sentences to test\n",
    "for i in range(20):\n",
    "    input_seq = input_tensor[i:i+1]\n",
    "    decoded = decode_sequence(input_seq)\n",
    "    \n",
    "    print(f\"Input    : {input_texts[i]}\")\n",
    "    print(f\"Predicted: {decoded}\")\n",
    "    print(f\"Target   : {target_texts[i].replace('<start>', '').replace('<end>', '').strip()}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
