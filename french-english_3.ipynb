{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a458d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f4045e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Load and Clean Data\n",
    "def load_data(path='fra.txt', num_examples = 50000):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        lines = f.read().strip().split('\\n')\n",
    "    \n",
    "    pairs = [line.split('\\t')[:2] for line in lines[:num_examples]]\n",
    "    \n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    for eng, fra in pairs:\n",
    "        input_texts.append(eng)\n",
    "        target_texts.append(f\"<start> {fra} <end>\")\n",
    "    \n",
    "    return input_texts, target_texts\n",
    "\n",
    "input_texts, target_texts = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c00a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Tokenize\n",
    "input_tokenizer = Tokenizer(filters='')\n",
    "target_tokenizer = Tokenizer(filters='')\n",
    "\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "target_tokenizer.fit_on_texts(target_texts)\n",
    "\n",
    "input_seqs = input_tokenizer.texts_to_sequences(input_texts)\n",
    "target_seqs = target_tokenizer.texts_to_sequences(target_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae96fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: (50000, 7)\n",
      "Target tensor shape: (50000, 14)\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Pad sequences\n",
    "input_tensor = pad_sequences(input_seqs, padding='post')\n",
    "target_tensor = pad_sequences(target_seqs, padding='post')\n",
    "\n",
    "print(\"Input tensor shape:\", input_tensor.shape)\n",
    "print(\"Target tensor shape:\", target_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "394fc3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input vocab size: 9130\n",
      "Target vocab size: 17458\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Vocabulary Sizes\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n",
    "\n",
    "print(\"Input vocab size:\", input_vocab_size)\n",
    "print(\"Target vocab size:\", target_vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8307f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf24ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 256\n",
    "units = 512\n",
    "\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "target_vocab_size = len(target_tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0078fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb = Embedding(input_vocab_size, embedding_dim)(encoder_inputs)\n",
    "encoder_lstm = LSTM(units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "\n",
    "# Save encoder states to initialize decoder\n",
    "encoder_states = [state_h, state_c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0398a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(target_vocab_size, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(target_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c0302d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 256)    2337280     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 256)    4469248     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 512),        1574912     ['embedding[0][0]']              \n",
      "                                 (None, 512),                                                     \n",
      "                                 (None, 512)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 512),  1574912     ['embedding_1[0][0]',            \n",
      "                                 (None, 512),                     'lstm[0][1]',                   \n",
      "                                 (None, 512)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 17458)  8955954     ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,912,306\n",
      "Trainable params: 18,912,306\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc4a040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first <start> token from target and prepare as labels\n",
    "decoder_target_data = target_tensor[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e8a3b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 24s 33ms/step - loss: 2.0670 - val_loss: 2.1116\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 1.4513 - val_loss: 1.8227\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 1.1630 - val_loss: 1.6864\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 0.9703 - val_loss: 1.6299\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 0.8210 - val_loss: 1.5959\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 0.6986 - val_loss: 1.5701\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 0.5953 - val_loss: 1.5694\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 0.5061 - val_loss: 1.5693\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 0.4300 - val_loss: 1.5633\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 20s 32ms/step - loss: 0.3652 - val_loss: 1.5778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18b134cf6a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "model.fit(\n",
    "    [input_tensor, target_tensor[:, :-1]],\n",
    "    tf.expand_dims(decoder_target_data, -1),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4201a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder model for inference (takes input sentence, returns hidden states)\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1742dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder inputs\n",
    "decoder_state_input_h = Input(shape=(units,))\n",
    "decoder_state_input_c = Input(shape=(units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# Decoder embedding\n",
    "dec_emb_inf = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# LSTM with previous states\n",
    "decoder_outputs_inf, state_h_inf, state_c_inf = decoder_lstm(\n",
    "    dec_emb_inf, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states_inf = [state_h_inf, state_c_inf]\n",
    "decoder_outputs_inf = decoder_dense(decoder_outputs_inf)\n",
    "\n",
    "# Full decoder inference model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs_inf] + decoder_states_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cefb8592",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_idx_word = {i: w for w, i in target_tokenizer.word_index.items()}\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Start with <start> token\n",
    "    target_seq = np.array([[target_tokenizer.word_index['<start>']]])\n",
    "\n",
    "    decoded_sentence = ''\n",
    "    stop_condition = False\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample the token with highest probability (greedy search)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = target_idx_word.get(sampled_token_index, '')\n",
    "\n",
    "        if sampled_word == '<end>' or len(decoded_sentence.split()) > 50:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            decoded_sentence += ' ' + sampled_word\n",
    "\n",
    "        # Update the target sequence and states\n",
    "        target_seq = np.array([[sampled_token_index]])\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82847089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Input    : Go.\n",
      "Predicted: en route !\n",
      "Target   : Va !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Input    : Go.\n",
      "Predicted: en route !\n",
      "Target   : Marche.\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Input    : Go.\n",
      "Predicted: en route !\n",
      "Target   : En route !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Input    : Go.\n",
      "Predicted: en route !\n",
      "Target   : Bouge !\n",
      "--------------------------------------------------\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Input    : Hi.\n",
      "Predicted: salut !\n",
      "Target   : Salut !\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Pick 5 random sentences to test\n",
    "for i in range(5):\n",
    "    input_seq = input_tensor[i:i+1]\n",
    "    decoded = decode_sequence(input_seq)\n",
    "    \n",
    "    print(f\"Input    : {input_texts[i]}\")\n",
    "    print(f\"Predicted: {decoded}\")\n",
    "    print(f\"Target   : {target_texts[i].replace('<start>', '').replace('<end>', '').strip()}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07fa90ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class BahdanauAttention(Layer):\n",
    "    def __init__(self, units):\n",
    "        super().__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(query_with_time_axis)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, tf.squeeze(attention_weights, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4929d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super().__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = tf.keras.layers.LSTM(dec_units, return_sequences=True, return_state=True)\n",
    "        self.attention = BahdanauAttention(dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        x = self.embedding(x)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state_h, state_c = self.lstm(x)\n",
    "        x = self.fc(output)\n",
    "        return x, state_h, state_c, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc1c4732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_attention(attention, input_sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(attention, xticklabels=input_sentence.split(), yticklabels=predicted_sentence.split(), cmap='viridis')\n",
    "    plt.xlabel('Input')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title(\"Attention Heatmap\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5bea91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_curves(history):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    if 'val_loss' in history.history:\n",
    "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy (optional)\n",
    "    if 'accuracy' in history.history:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "        if 'val_accuracy' in history.history:\n",
    "            plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
